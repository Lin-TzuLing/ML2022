{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMb22pgH7l3VGbUkznOxuvO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"V9UQK9SR3Dyh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670691151934,"user_tz":-480,"elapsed":16869,"user":{"displayName":"林子淩","userId":"07693141841849975374"}},"outputId":"5c6ecb1a-8ac3-4b3e-ec11-07abec296d10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.5.1)\n","Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.20.2)\n","Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from levenshtein==0.20.2->jiwer) (2.13.4)\n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers,Model\n","from tensorflow.keras.optimizers import SGD, Adam\n","from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display\n","!pip install jiwer\n","from jiwer import wer\n","import os"]},{"cell_type":"code","source":["train_path = './drive/MyDrive/MLHW3/data/new_train/'\n","label_path = './drive/MyDrive/MLHW3/data/train-toneless.csv'\n","model_path = 'model.h5'\n","wer_model_path = 'wer_model.h5'"],"metadata":{"id":"TKEIoDev4JTY","executionInfo":{"status":"ok","timestamp":1670691151935,"user_tz":-480,"elapsed":8,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["label_df = pd.read_csv(label_path)\n","label_df = label_df.applymap(str)\n","split = int(len(label_df) * 0.90)\n","label_train = label_df[:split]\n","label_valid = label_df[split:]\n","if __name__ == \"__main__\":\n","    print(\"Size of the train set: {}\".format(len(label_train)))\n","    print(\"Size of the valid set: {}\".format(len(label_valid)))\n","\n","c_set = set()\n","texts = label_df['text']\n","for text in texts:\n","    for c in text:\n","        c_set.add(c.lower())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93HwTqg64v0E","executionInfo":{"status":"ok","timestamp":1670691152392,"user_tz":-480,"elapsed":464,"user":{"displayName":"林子淩","userId":"07693141841849975374"}},"outputId":"417cba00-2390-4b8b-c74d-4c28aad277b7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the train set: 2807\n","Size of the valid set: 312\n"]}]},{"cell_type":"code","source":["# The set of characters accepted in the transcription.\n","# characters = list(c_set)\n","characters = [x for x in 'abcdefghijklmnopqrstuvwxyz ']\n","# Mapping characters to integers\n","char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n","# Mapping integers back to original characters\n","num_to_char = keras.layers.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",")\n","if __name__ == \"__main__\":\n","    print(\"The vocabulary is: {}\".format(char_to_num.get_vocabulary()))\n","    print(\"size : {}\".format(char_to_num.vocabulary_size()))\n","\n","# An integer scalar Tensor. The window length in samples.\n","frame_length = 128\n","# An integer scalar Tensor. The number of samples to step.\n","frame_step = 128\n","# An integer scalar Tensor. The size of the FFT to apply.\n","# If not provided, uses the smallest power of 2 enclosing frame_length.\n","fft_length = 128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U4jS45Hs41lh","executionInfo":{"status":"ok","timestamp":1670691152394,"user_tz":-480,"elapsed":15,"user":{"displayName":"林子淩","userId":"07693141841849975374"}},"outputId":"c1e35263-33c2-442a-f6ef-e1ede3f5d011"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n","size : 28\n"]}]},{"cell_type":"code","source":["def encode_single_sample(filename, label):\n","    # --------------------------process audio ----------------------------\n","    # 1. Read wav file\n","    file = tf.io.read_file(train_path + filename + \".wav\")\n","    # 2. Decode the wav file\n","    audio, _ = tf.audio.decode_wav(file)\n","    audio = tf.squeeze(audio, axis=-1)\n","    # 3. Change type to float\n","    audio = tf.cast(audio, tf.float32)\n","    # 4. Get the spectrogram\n","    spectrogram = tf.signal.stft(\n","        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n","    )\n","    # 5. Only need the magnitude, applying tf.abs\n","    spectrogram = tf.abs(spectrogram)\n","    spectrogram = tf.math.pow(spectrogram, 0.5)\n","\n","    # 6. normalization\n","    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n","    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n","    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n","\n","    # --------------------------process label ----------------------------\n","    # 7. Convert label to Lower case\n","    label = tf.strings.lower(label)\n","    # 8. Split the label\n","    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n","    # 9. Map the characters in label to numbers\n","    label = char_to_num(label)\n","    # 10. Return a dict as our model is expecting two inputs\n","    return spectrogram, label\n","\n","\n","batch_size = 8\n","lr = 1e-4"],"metadata":{"id":"9q2cLi2N44f1","executionInfo":{"status":"ok","timestamp":1670691152396,"user_tz":-480,"elapsed":11,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# training dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(label_train[\"id\"]), list(label_train[\"text\"]))\n",")\n","train_dataset = (\n","    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")\n","\n","# Define the validation dataset\n","validation_dataset = tf.data.Dataset.from_tensor_slices(\n","    (list(label_valid[\"id\"]), list(label_valid[\"text\"]))\n",")\n","validation_dataset = (\n","    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n","    .padded_batch(batch_size)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")"],"metadata":{"id":"_j-u0ScD47ox","executionInfo":{"status":"ok","timestamp":1670691153749,"user_tz":-480,"elapsed":1363,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def CTCLoss(y_true, y_pred):\n","    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n","    return loss"],"metadata":{"id":"Gsiv14aP5ANZ","executionInfo":{"status":"ok","timestamp":1670691153751,"user_tz":-480,"elapsed":10,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def myModel(input_dim, output_dim, rnn_layers=3, rnn_units=128):\n","\n","    # input\n","    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n","    # Expand the dimension to use 2D CNN.\n","    # x = layers.Embedding(input_dim=input_dim, output_dim=64)(input_spectrogram)\n","    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n","    # Convolution layer 1\n","    x = layers.Conv2D(filters=16,kernel_size=[8, 8], strides=[1, 1],\n","                      padding=\"same\", use_bias=False, name=\"conv_1\")(x)\n","    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n","    x = layers.ReLU(name=\"conv_1_relu\")(x)\n","    x = layers.Conv2D(filters=16, kernel_size=[5, 5], strides=[1, 1],\n","                      padding=\"same\", use_bias=False, name=\"conv_2\")(x)\n","    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n","    x = layers.ReLU(name=\"conv_2_relu\")(x)\n","    # Reshape\n","    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n","    x = layers.Dense(units=1024, name=\"dense_1\")(x)\n","    x = layers.ReLU(name=\"dense_1_relu\")(x)\n","    x = layers.Dropout(rate=0.5)(x)\n","    # RNN layer\n","    for i in range(1, rnn_layers + 1):\n","        RNN = layers.GRU(units=rnn_units, activation=\"tanh\", recurrent_activation=\"sigmoid\",\n","                               use_bias=True, return_sequences=True, reset_after=True, name=f\"gru_{i}\")\n","        x = layers.Bidirectional(RNN, name=f\"bidirectional_{i}\", merge_mode=\"concat\")(x)\n","        x = layers.Attention()([x, x])\n","        if i < rnn_layers:\n","            x = layers.Dropout(rate=0.5)(x)\n","     # Dense layer\n","    # x = layers.Attention()([x, x])\n","    x = layers.Dense(units=rnn_units * 2, name=\"dense_2\")(x)\n","    x = layers.ReLU(name=\"dense_2_relu\")(x)\n","    x = layers.Dropout(rate=0.5)(x)\n","    # Classification layer\n","    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n","    # Model\n","    model = Model(input_spectrogram, output, name=\"CNN_GRU_model\")\n","    # Optimizer\n","    optim = Adam(learning_rate=lr)\n","    # Compile the model and return\n","    model.compile(optimizer=optim, loss=CTCLoss)\n","    return model\n","\n","\n","\n","# build model\n","model = myModel(input_dim=fft_length // 2 + 1,\n","                output_dim=char_to_num.vocabulary_size(),\n","                rnn_units=128)\n","\n","\n","model.summary(line_length=110)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lxzo0WW5DNn","executionInfo":{"status":"ok","timestamp":1670691156571,"user_tz":-480,"elapsed":2828,"user":{"displayName":"林子淩","userId":"07693141841849975374"}},"outputId":"83653ea3-141d-4cf2-ddbc-514344aaf23b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"CNN_GRU_model\"\n","______________________________________________________________________________________________________________\n"," Layer (type)                       Output Shape            Param #      Connected to                         \n","==============================================================================================================\n"," input (InputLayer)                 [(None, None, 65)]      0            []                                   \n","                                                                                                              \n"," expand_dim (Reshape)               (None, None, 65, 1)     0            ['input[0][0]']                      \n","                                                                                                              \n"," conv_1 (Conv2D)                    (None, None, 65, 16)    1024         ['expand_dim[0][0]']                 \n","                                                                                                              \n"," conv_1_bn (BatchNormalization)     (None, None, 65, 16)    64           ['conv_1[0][0]']                     \n","                                                                                                              \n"," conv_1_relu (ReLU)                 (None, None, 65, 16)    0            ['conv_1_bn[0][0]']                  \n","                                                                                                              \n"," conv_2 (Conv2D)                    (None, None, 65, 16)    6400         ['conv_1_relu[0][0]']                \n","                                                                                                              \n"," conv_2_bn (BatchNormalization)     (None, None, 65, 16)    64           ['conv_2[0][0]']                     \n","                                                                                                              \n"," conv_2_relu (ReLU)                 (None, None, 65, 16)    0            ['conv_2_bn[0][0]']                  \n","                                                                                                              \n"," reshape (Reshape)                  (None, None, 1040)      0            ['conv_2_relu[0][0]']                \n","                                                                                                              \n"," dense_1 (Dense)                    (None, None, 1024)      1065984      ['reshape[0][0]']                    \n","                                                                                                              \n"," dense_1_relu (ReLU)                (None, None, 1024)      0            ['dense_1[0][0]']                    \n","                                                                                                              \n"," dropout (Dropout)                  (None, None, 1024)      0            ['dense_1_relu[0][0]']               \n","                                                                                                              \n"," bidirectional_1 (Bidirectional)    (None, None, 256)       886272       ['dropout[0][0]']                    \n","                                                                                                              \n"," attention (Attention)              (None, None, 256)       0            ['bidirectional_1[0][0]',            \n","                                                                          'bidirectional_1[0][0]']            \n","                                                                                                              \n"," dropout_1 (Dropout)                (None, None, 256)       0            ['attention[0][0]']                  \n","                                                                                                              \n"," bidirectional_2 (Bidirectional)    (None, None, 256)       296448       ['dropout_1[0][0]']                  \n","                                                                                                              \n"," attention_1 (Attention)            (None, None, 256)       0            ['bidirectional_2[0][0]',            \n","                                                                          'bidirectional_2[0][0]']            \n","                                                                                                              \n"," dropout_2 (Dropout)                (None, None, 256)       0            ['attention_1[0][0]']                \n","                                                                                                              \n"," bidirectional_3 (Bidirectional)    (None, None, 256)       296448       ['dropout_2[0][0]']                  \n","                                                                                                              \n"," attention_2 (Attention)            (None, None, 256)       0            ['bidirectional_3[0][0]',            \n","                                                                          'bidirectional_3[0][0]']            \n","                                                                                                              \n"," dense_2 (Dense)                    (None, None, 256)       65792        ['attention_2[0][0]']                \n","                                                                                                              \n"," dense_2_relu (ReLU)                (None, None, 256)       0            ['dense_2[0][0]']                    \n","                                                                                                              \n"," dropout_3 (Dropout)                (None, None, 256)       0            ['dense_2_relu[0][0]']               \n","                                                                                                              \n"," dense (Dense)                      (None, None, 29)        7453         ['dropout_3[0][0]']                  \n","                                                                                                              \n","==============================================================================================================\n","Total params: 2,625,949\n","Trainable params: 2,625,885\n","Non-trainable params: 64\n","______________________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# decode output of model\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n","    # Iterate over the results and get back the text\n","    output_text = []\n","    for result in results:\n","        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n","        output_text.append(result)\n","    return output_text"],"metadata":{"id":"RP2gvEUP5DPx","executionInfo":{"status":"ok","timestamp":1670691156571,"user_tz":-480,"elapsed":10,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# callback for validation wer score and save wer model\n","wer_history = [1.0]\n","class CallbackEval(keras.callbacks.Callback):\n","    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n","    def __init__(self, dataset):\n","        super().__init__()\n","        self.dataset = dataset\n","\n","    def on_epoch_end(self, epoch: int, logs=None):\n","        predictions = []\n","        targets = []\n","        for batch in self.dataset:\n","            X, y = batch\n","            batch_predictions = model.predict(X)\n","            batch_predictions = decode_batch_predictions(batch_predictions)\n","            predictions.extend(batch_predictions)\n","            for label in y:\n","                label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","                targets.append(label)\n","        wer_score = wer(targets, predictions)\n","        if wer_score < min(wer_history):\n","            model.save(wer_model_path)\n","            print('save wer model')\n","        wer_history.append(wer_score)\n","        print(\"-\" * 100)\n","        print(\"Word Error Rate: {}\".format(wer_score))\n","        print(\"-\" * 100)\n","        for i in np.random.randint(0, len(predictions), 2):\n","            print(\"Target : {}\".format(targets[i]))\n","            print(\"Prediction: {}\".format(predictions[i]))\n","            print(\"-\" * 100)"],"metadata":{"id":"VLmgh5VJ5DSA","executionInfo":{"status":"ok","timestamp":1670691156572,"user_tz":-480,"elapsed":10,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# plot history\n","def plot_history(history, train_metrics, val_metrics):\n","    plt.plot(history.history.get(train_metrics), '-o')\n","    plt.plot(history.history.get(val_metrics), '-r')\n","    plt.ylabel(train_metrics)\n","    plt.xlabel('Epochs')\n","    plt.legend(['train','validation'])\n","\n","\n","callback_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n","callback_ckpt = ModelCheckpoint(model_path, verbose=1,\n","                                monitor='val_loss', save_best_only=True, mode='min')\n","callback_lrScheduler = ReduceLROnPlateau(monitor='val_loss', patience=3,\n","                                         verbose=1, factor=0.5, min_lr=0.00001)\n","# Define the number of epochs.\n","epochs = 350\n","# Callback function to check transcription on the val set.\n","validation_callback = CallbackEval(validation_dataset)"],"metadata":{"id":"scgHFuoP5DUu","executionInfo":{"status":"ok","timestamp":1670691156573,"user_tz":-480,"elapsed":10,"user":{"displayName":"林子淩","userId":"07693141841849975374"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Train model\n","    history = model.fit(\n","        train_dataset,\n","        validation_data=validation_dataset,\n","        epochs=epochs,\n","        callbacks=[validation_callback, callback_stop, callback_ckpt],\n","        # callbacks=[validation_callback, callback_stop, callback_ckpt, callback_lrScheduler],\n","    )\n","    # plot history\n","    plt.figure(figsize=(12,4))\n","    plt.subplot(1,2,1)\n","    plot_history(history, 'loss', 'val_loss')\n","    plt.subplot(1,2,2)\n","    wer_history = wer_history[1:]\n","    plt.plot(list(np.arange(len(wer_history))),wer_history)\n","    plt.ylabel('wer score')\n","    plt.xlabel('Epochs')\n","    plt.legend(['valid'])\n","    plt.show()\n","\n","    # check results on validation samples\n","    predictions = []\n","    targets = []\n","    for batch in validation_dataset:\n","        X, y = batch\n","        batch_predictions = model.predict(X)\n","        batch_predictions = decode_batch_predictions(batch_predictions)\n","        predictions.extend(batch_predictions)\n","        for label in y:\n","            label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n","            targets.append(label)\n","    wer_score = wer(targets, predictions)\n","    print(\"-\" * 100)\n","    print(f\"Word Error Rate: {wer_score:.4f}\")\n","    print(\"-\" * 100)\n","    for i in np.random.randint(0, len(predictions), 5):\n","        print(f\"Target    : {targets[i]}\")\n","        print(f\"Prediction: {predictions[i]}\")\n","        print(\"-\" * 100)\n","\n","    print('training done')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q521mT1L5DWd","outputId":"2b104823-692b-4eeb-be2b-dedc26003b4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/350\n","  1/351 [..............................] - ETA: 4:22:10 - loss: 2908.0156"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YlLr0YwK5DZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Kx2ovSph5DbJ"},"execution_count":null,"outputs":[]}]}